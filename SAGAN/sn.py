# -*- coding: utf-8 -*-
"""sn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WlvUBMRTsAEZDDE2tPlk4-YqLwrPTtEL

# Self Attention GAN
- Data
- Model
  - Generator
  - Discriminator
  - Loss
- Tool
  - FID
  - Visualize
  - GIF
- Train
  - Checkpoint
  - train_step()
  - train()
- Grading
  - Restore model/ckpt
  - Show image grid
  - Show mean FID

# Install Tensorflow & Mount Drive
"""

# Commented out IPython magic to ensure Python compatibility.
# Tensorboard
! pip install --upgrade tensorflow-gpu tensorboard

# To generate GIFs
!pip install -q imageio

# Load the TensorBoard notebook extension
# %reload_ext tensorboard
# %load_ext tensorboard

import tensorflow as tf
print(tf.__version__)
print(str(tf.test.is_gpu_available()))

from google.colab import drive
drive.mount('/content/drive/')
# %cd /content/drive/'My Drive'/GAN/CSE676_Project1/SAGAN/
!ls

"""# Import and Parameters"""

import os
import PIL
import glob
import time
import imageio
import datetime
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.keras import metrics
print(tf.__version__)

# For FID
from numpy import cov
from numpy import trace
from numpy import iscomplexobj
from numpy import asarray
from numpy.random import shuffle
from scipy.linalg import sqrtm
from skimage.transform import resize
from keras.datasets import cifar10

# For GIF
from IPython import display
from google.colab import files

begin = 0
epochs = 150
batch_size = 64
lamda = 10



inception3 = tf.keras.applications.InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))

"""# Data"""

def preprocess(x, y):
    x = tf.cast(x, tf.float32)
    x = x / 127.5 - 1
    y = tf.one_hot(y, depth=10, on_value=1.0, off_value=0.0, axis=-1) 
    return x, y

(x,y), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()
print(x.shape, y.shape, x_test.shape, y_test.shape)

x = x.reshape(x.shape[0], 32, 32, 3).astype('float32')
x_test = x_test.reshape(x_test.shape[0], 32, 32, 3).astype('float32')

batch_train = 1024
batch_test = 1024

training = tf.data.Dataset.from_tensor_slices((x, y))
train_data_ = training.map(preprocess).shuffle(50000).batch(batch_train).repeat()
train_data_it = iter(train_data_)

testing = tf.data.Dataset.from_tensor_slices((x_test, y_test))
test_data_ = testing.map(preprocess).batch(batch_test).repeat()
test_data_it = iter(test_data_)

# training = tf.data.Dataset.from_tensor_slices((x, y))
train_data = training.map(preprocess).shuffle(50000).batch(batch_size)

# testing = tf.data.Dataset.from_tensor_slices((x_test, y_test))
test_data = testing.map(preprocess).batch(batch_size)


train_img = next(iter(train_data))
test_img = next(iter(test_data))
img, label = train_img
print(img.shape, label.shape)
print(img[0].shape, img[0].dtype, img[0].numpy().min(), img[0].numpy().max())
print(label[0].numpy())

"""# Model

## Spectral Normalization
reference:

https://github.com/thisisiron/spectral_normalization-tf2/blob/master/sn.py
"""

class SpectralNormalization(tf.keras.layers.Wrapper):
    def __init__(self, layer, iteration=1, eps=1e-12, training=True, **kwargs):
        self.iteration = iteration
        self.eps = eps
        self.do_power_iteration = training
        if not isinstance(layer, tf.keras.layers.Layer):
            raise ValueError(
                'Please initialize `TimeDistributed` layer with a '
                '`Layer` instance. You passed: {input}'.format(input=layer))
        super(SpectralNormalization, self).__init__(layer, **kwargs)

    def build(self, input_shape):
        self.layer.build(input_shape)

        self.w = self.layer.kernel
        self.w_shape = self.w.shape.as_list()

        self.v = self.add_weight(shape=(1, self.w_shape[0] * self.w_shape[1] * self.w_shape[2]),
                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),
                                 trainable=False,
                                 name='sn_v',
                                 dtype=tf.float32)

        self.u = self.add_weight(shape=(1, self.w_shape[-1]),
                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),
                                 trainable=False,
                                 name='sn_u',
                                 dtype=tf.float32)

        super(SpectralNormalization, self).build()

    def call(self, inputs):
        self.update_weights()
        output = self.layer(inputs)
        self.restore_weights()  # Restore weights because of this formula "W = W - alpha * W_SN`"
        return output
    
    def update_weights(self):
        w_reshaped = tf.reshape(self.w, [-1, self.w_shape[-1]])
        
        u_hat = self.u
        v_hat = self.v  # init v vector

        if self.do_power_iteration:
            for _ in range(self.iteration):
                v_ = tf.matmul(u_hat, tf.transpose(w_reshaped))
                v_hat = v_ / (tf.reduce_sum(v_**2)**0.5 + self.eps)

                u_ = tf.matmul(v_hat, w_reshaped)
                u_hat = u_ / (tf.reduce_sum(u_**2)**0.5 + self.eps)

        sigma = tf.matmul(tf.matmul(v_hat, w_reshaped), tf.transpose(u_hat))
        self.u.assign(u_hat)
        self.v.assign(v_hat)

        self.layer.kernel.assign(self.w / sigma)

    def restore_weights(self):
        self.layer.kernel.assign(self.w)

"""## Attention"""

def attention_flatten(x) :
    batchsize = -1 if x.shape[0] == None else x.shape[0]
    outputshape = [batchsize, x.shape[1]*x.shape[1], x.shape[3]] 
  
    reshape = tf.reshape(x, shape=outputshape)
    
    return reshape
      
  
class Attention(keras.Model):

    def __init__(self, channel, flag=False):
        super(Attention, self).__init__()
        self.channel = channel
        self.flag = flag
        self.conv_f = keras.layers.Conv2D(self.channel//8, 1, 1, 'valid') 
        self.conv_g = keras.layers.Conv2D(self.channel//8, 1, 1, 'valid') 
        self.conv_h = keras.layers.Conv2D(self.channel, 1, 1, 'valid') 
        self.conv_o = keras.layers.Conv2D(self.channel, 1, 1, 'valid') 
        self.gamma = tf.Variable(tf.zeros(shape=[1]))
        
    def call(self, x):
        f = self.conv_f(x)
        g = self.conv_g(x)
        h = self.conv_h(x)
        
        f, g, h = attention_flatten(f), attention_flatten(g), attention_flatten(h)
        
        mul = tf.matmul(g, f, transpose_b=True)
        
        attention_map = tf.nn.softmax(mul, axis=-1)

        o = tf.matmul(attention_map, h)
        
        outputshape = x.shape
        
        if x.shape[0] == None:
            outputshape = [-1, x.shape[1], x.shape[2], x.shape[3]]
        
        o = tf.reshape(o, shape=outputshape) 
        
        o = self.conv_o(o)

        x = self.gamma * o + x
        
        if self.flag == True:
              return x, attention_map
        else:
              return x

"""## Generator"""

class Generator(keras.Model):

    def __init__(self):
        super(Generator, self).__init__()
        # input img is [b, 100]
        
        self.channel = 512
        self.dense = keras.layers.Dense(4*4*self.channel)  
        
        self.conv1 = SpectralNormalization( keras.layers.Conv2DTranspose(256, 4, 2, 'same', use_bias=False) )
        self.batch1 = keras.layers.BatchNormalization()
        
        self.conv2 = SpectralNormalization( keras.layers.Conv2DTranspose(128, 4, 2, 'same', use_bias=False) )
        self.batch2 = keras.layers.BatchNormalization()
        
        self.conv3 = SpectralNormalization( keras.layers.Conv2DTranspose(64, 4, 2, 'same', use_bias=False) )
        self.batch3 = keras.layers.BatchNormalization()
        
        self.attention= Attention(channel=256, flag=True)
        
        self.conv4 = keras.layers.Conv2DTranspose(3, 3, 1, 'same', use_bias=False)
        
        
        return

    def call(self, inputs, training=None):
        # [b, 100] => [b, 4, 4, 512]
        x = self.dense(inputs)
        x = tf.reshape(x, shape = [-1, 4, 4, 512])
        x = tf.nn.leaky_relu(x)
        
        # [b, 4, 4, 512] => [b, 8, 8, 256]
        x = self.conv1(x)
        x = self.batch1(x, training = training)
        x = tf.nn.leaky_relu(x)
        
        x, gmap = self.attention(x)
        
        # [b, 8, 8, 256] => [b, 16, 16, 128]
        x = self.conv2(x)
        x = self.batch2(x, training = training)
        x = tf.nn.leaky_relu(x)
        
        # [b, 16, 16, 128] => [b, 32, 32, 64]
        x = self.conv3(x)
        x = self.batch3(x, training = training)
        x = tf.nn.leaky_relu(x)
        
        # [b, 32, 32, 64] => [b, 32, 32, 3]
        x = self.conv4(x)
        x = tf.tanh(x)
        
        return x, gmap
      
    def model(self):  
        x = keras.Input(shape=(110,))
        return keras.Model(inputs=[x], outputs=self.call(x))

"""## Discriminator"""

class Discriminator(keras.Model):

    def __init__(self):
        super(Discriminator, self).__init__()
        
        self.conv1 = SpectralNormalization( keras.layers.Conv2D(64, 4, 2, 'same') )

        self.conv2 = SpectralNormalization( keras.layers.Conv2D(128, 4, 2, 'same') )
        
        self.attention= Attention(channel=128, flag=False)
        
        self.conv3 = SpectralNormalization( keras.layers.Conv2D(256, 4, 2, 'same') )
        
        self.conv4 = keras.layers.Conv2D(512, 3, 1, 'same') 

        self.flatten = keras.layers.Flatten()

        self.dense = keras.layers.Dense(1)
        return

    def call(self, inputs, training=None):
        inp, label = inputs
        # [b, 32, 32, 3] => [b, 16, 16, 64]
        x = self.conv1(inp)
        x = tf.nn.leaky_relu(x)
        
        # [b, 16, 16, 64] => [b, 8, 8, 128]
        x = self.conv2(x)
        x = tf.nn.leaky_relu(x)
        
        x = self.attention(x)
        
        # [b, 8, 8, 128] => [b, 4, 4, 256]
        x = self.conv3(x)
        x = tf.nn.leaky_relu(x)
        
        # [b, 4, 4, 256] => [b, 4, 4, 512]
        x = self.conv4(x)
        x = tf.nn.leaky_relu(x)
        
        # [b, 4, 4, 512] => [b, 4*4*512]
        x = self.flatten(x)
        
        x = tf.concat([x, label], axis=-1)
        
        # [b, 2*2*256] => [b, 1]
        x = self.dense(x)
        
        return x

"""## Test Model"""

generator = Generator()
noise = tf.random.normal([64, 110])
generated_image, g_map = generator(noise, training=False)
plt.imshow(generated_image[0, :, :, 2])
print('geneated_img:', generated_image.shape, generated_image.dtype, tf.reduce_min(generated_image), tf.reduce_max(generated_image))
print('g_map1:', g_map.shape, g_map.dtype, tf.reduce_min(g_map), tf.reduce_max(g_map))


discriminator = Discriminator()
decision = discriminator([generated_image, tf.random.normal([64, 10])])
print ('decision:', decision.shape, tf.reduce_min(decision), tf.reduce_min(decision))
# discriminator.build(input_shape=[batch_size, 32, 32, 3])
# discriminator.summary()

"""## Loss"""

loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)
def generator_loss(gen_output):
    
    loss = loss_obj(tf.ones_like(gen_output), gen_output)
    
    return tf.reduce_mean(loss)

  
def gradient_penalty(discriminator, img, gen_img, label):
    t = tf.random.uniform(shape=img.shape, minval=0, maxval=1)
    interplate = t * img + (1 - t) * gen_img
    with tf.GradientTape() as tape:
        tape.watch([interplate])
        mix_output = discriminator([interplate, label])
    grad = tape.gradient(mix_output, interplate)
    
    norm = tf.norm(tf.reshape(grad,[grad.shape[0], -1]), axis=1)
  
    gp = tf.square(norm - 1.)
    
    return gp

  
  
def discriminator_loss(discriminator, img, gen_img, label, training=True):
  
    real_output = discriminator([img, label], training=training)
    gen_output = discriminator([gen_img, label], training=training)
    loss1 = loss_obj(tf.ones_like(real_output), real_output)
    loss2 = loss_obj(tf.zeros_like(gen_output), gen_output)
    penalty = gradient_penalty(discriminator, img, gen_img, label)
    
    loss = tf.reduce_mean(loss1) + tf.reduce_mean(loss2) + lamda * tf.reduce_mean(penalty)
    
    return loss

"""# Tool

## FID 
referrence : https://machinelearningmastery.com/how-to-implement-the-frechet-inception-distance-fid-from-scratch/
"""

def scale_images(images, new_shape):
    images_list = list()
    for image in images:
        # resize with nearest neighbor interpolation
        new_image = resize(image, new_shape, 0)
        # store
        images_list.append(new_image)
        
    return asarray(images_list)

def calculate_fid(model, images1, images2):
	# calculate activations
	act1 = model.predict(images1)
	act2 = model.predict(images2)
	# calculate mean and covariance statistics
	mu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)
	mu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)
	# calculate sum squared difference between means
	ssdiff = np.sum((mu1 - mu2)**2.0)
	# calculate sqrt of product between cov
	covmean = sqrtm(sigma1.dot(sigma2))
	# check and correct imaginary numbers from sqrt
	if iscomplexobj(covmean):
		covmean = covmean.real
	# calculate score
	fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)
    
	return fid

def calculate_fid_with_img(img1, img2):
    img1 = scale_images(img1, (299,299,3))
    img2 = scale_images(img2, (299,299,3))
    img1 = tf.keras.applications.inception_v3.preprocess_input(img1)
    img2 = tf.keras.applications.inception_v3.preprocess_input(img2)
    # calcufate fid
    fid = calculate_fid(inception3, img1, img2)

    return fid

def calculate_all_fid(generator,  real_img, training):
    img, label = real_img
    label = tf.squeeze(label)
    seed = tf.concat([tf.random.normal([img.shape[0], 100]), label], axis=-1)
    fake_img, gmap = generator(seed, training=training)
    fid = calculate_fid_with_img(img, fake_img)
    
    return fid

# all_score = 0
# step = 1
# for i in range(step):
#     img1 = next(test_data_it)[0]
#     img2 = next(train_data_it)[0]
#     score = calculate_fid_with_img(img1, img2)
#     all_score += score
#     print('batch_train:', batch_train, ', batch_test:', batch_test, ', step:', i, ', fid score:', score)

# print('batch_train:', batch_train, ', batch_test:', batch_test, 'average fid score:', all_score / step)

"""## For visualization"""

def generate_and_save_images(model, epoch, seed, path, flag=False):
    predictions, gmap = model(seed, training=False)
    #   print(predictions.shape, predictions[0].shape,  predictions[0].dtype,  tf.reduce_min(predictions[0]),  tf.reduce_max(predictions[0]))

    fig = plt.figure(figsize=(8,8))

    for i in range(64):
        plt.subplot(8, 8, i+1)
        plt.imshow(predictions[i] * 0.5 + 0.5 )
        plt.axis('off')
    plt.savefig(path + '{:04d}.png'.format(epoch))
    if flag == True:
      plt.show()
    plt.close()

def display_image(epoch_no):
    return PIL.Image.open('./train/sn_epoch_{:04d}.png'.format(epoch_no))

"""## Make GIF

reference: https://www.tensorflow.org/tutorials/generative/dcgan
"""

def make_gif():
  anim_file = 'sn.gif'

  with imageio.get_writer(anim_file, mode='I') as writer:
      filenames = glob.glob("./train/sn_epoch_*.png")
      filenames = sorted(filenames)
      last = -1
      for i,filename in enumerate(filenames):
          frame = 2*(i**0.5)
          if round(frame) > round(last):
              last = frame
          else:
              continue
          image = imageio.imread(filename)
          writer.append_data(image)
      image = imageio.imread(filename)
      writer.append_data(image)

  import IPython
  if IPython.version_info > (6,2,0,''):
      display.Image(filename=anim_file)

"""# Train

## Initialize model & optimizer
"""

Gen = Generator()
Dis = Discriminator()

g_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0, beta_2=0.9)
d_optimizer = tf.keras.optimizers.Adam(4e-4, beta_1=0, beta_2=0.9)

"""## Checkpoint"""

checkpoint_dir = './ckpt/sn/'
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
checkpoint = tf.train.Checkpoint(g_optimizer=g_optimizer, d_optimizer=d_optimizer, Gen=Gen, Dis=Dis)
print(checkpoint_prefix)

"""## Train_step"""

@tf.function
def train_step(real_img):
    img, label = real_img
    z = tf.random.normal([label.shape[0], 100])
    label = tf.squeeze(label)
    noise = tf.concat([z, label], axis=-1)
    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        gen_img, gmap = Gen(noise, training=True)
        gene_output = Dis([gen_img, label], training=True)
        gen_loss = generator_loss(gene_output)
        disc_loss = discriminator_loss(Dis, img, gen_img, label, training=True)

    grad_gen = gen_tape.gradient(gen_loss, Gen.trainable_variables)
    grad_dis = disc_tape.gradient(disc_loss, Dis.trainable_variables)
    g_optimizer.apply_gradients(zip(grad_gen, Gen.trainable_variables))
    d_optimizer.apply_gradients(zip(grad_dis, Dis.trainable_variables))

    return tf.reduce_mean(gen_loss), tf.reduce_mean(disc_loss)

"""## Train()"""

def train(train_dataset, begin, epochs, iteration, batch_size):
    start_time = time.time()
    print('batch_size:', batch_size,', begin_iteration:', iteration, ', batch_train:', batch_train, ', batch_test:', batch_test, ', epochs:', epochs, ', gp lamda:', lamda)
    print('Begin time:{}.'.format( time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())))
    
    # seed is for generate_and_save_images, should not be change durnig train time
    label_for_seed = tf.squeeze(tf.one_hot(tf.random.uniform([batch_size, 1], minval=0, maxval=9, dtype=tf.dtypes.int32), depth=10, on_value=1.0, off_value=0.0, axis=-1) )
    seed = tf.concat([tf.random.normal([batch_size, 100]), label_for_seed], axis=-1)
    
    total_gen_loss = total_dis_loss = 0
    per_it = 1000
    for epoch in range(begin, epochs):
        for step, img in enumerate(train_dataset):
            iteration += 1
            gen_loss, disc_loss = train_step(img)
            total_gen_loss += float(gen_loss)
            total_dis_loss += float(disc_loss)
            if iteration % per_it == 0:
                test_it = next(test_data_it)
                test_fid_score = calculate_all_fid(Gen, test_it, training=True)
                train_it = next(train_data_it)
                train_fid_score = calculate_all_fid(Gen, train_it, training=True)
                
                with train_summary_writer.as_default():
                    tf.summary.scalar('train_FID', train_fid_score, step=iteration)
                    tf.summary.scalar('test_FID', test_fid_score, step=iteration)
                    tf.summary.scalar('Generator', total_gen_loss / per_it, step=iteration)
                    tf.summary.scalar('Discriminator', total_dis_loss / per_it, step=iteration)
                print("Epoch: {}, iteration:{}, train_fid :{:.2f}, test_fid :{:.2f}, gene_loss: {:.2f}, disc_loss: {:.2f}.".format( epoch + 1, iteration, train_fid_score,test_fid_score,  total_gen_loss / per_it , total_dis_loss / per_it) )
                total_gen_loss = total_dis_loss = 0
                
        generate_and_save_images(Gen, epoch + 1, seed, './train/sn_epoch_')

        if (epoch + 1) % 10 == 0:
            checkpoint.save(file_prefix = checkpoint_prefix)
            print('Epoch: {}, Current time:{}, save checkpoint successfully. '.format(epoch + 1, time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())))

    end_time = time.time()
    total_sec = end_time - start_time
    hours = int((total_sec)/(60*60))
    minitues = int((total_sec/60 - hours*60))
    seconds = int(total_sec - hours*3600 - minitues*60)
    print('End time:{}, total use time:{}hours, {}minitues, {}seconds.'.format(time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()), hours, minitues, seconds))

"""## Test()"""

def test(test_dataset, epochs, batch_test):
    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))
    
    z = tf.random.normal([64, 100])
    label= tf.squeeze(tf.one_hot(tf.random.uniform([64, 1], minval=0, maxval=9, dtype=tf.dtypes.int32), depth=10, on_value=1.0, off_value=0.0, axis=-1) )
    noise = tf.concat([z, label], axis=-1)
    generate_and_save_images(Gen, epochs, noise, './final_')
    
    fid_test = 0
    i = 0
    for step, img in enumerate(test_dataset):
      # 1024 * 10
        fid = calculate_all_fid(Gen, img, training=False)
        fid_test += fid
        i += 1
        print('{:04d} / {:04d} test imgs, FID score : {:.2f}, please wait... '.format(i*batch_test, 10*batch_test, fid))
        if i >= 10:
            break
    fid_test /= 10.
    print('The average FID score on test data is:', fid_test)

log_dir = './logs/' + 'sn'
train_summary_writer = tf.summary.create_file_writer(log_dir)

# Commented out IPython magic to ensure Python compatibility.
# !kill 429
# %tensorboard --logdir ./logs

"""## Main()"""

def main():
#     checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))
    print("------------------------SN------------------------")
#     train(train_dataset, begin, epochs, iteration, batch_size):
    train(train_data, 0, epochs, 0, batch_size)
    print("\n\n------------------------Making GIF------------------------")
    make_gif()
    print("\n\n------------------------Testing------------------------")
    test(test_data, epochs, batch_test)

if __name__ == '__main__':
    Gen = Generator()
    Dis = Discriminator()

    g_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0, beta_2=0.9)
    d_optimizer = tf.keras.optimizers.Adam(4e-4, beta_1=0, beta_2=0.9)
    main()

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir ./all_logs

"""# For Grading

## Restore the best model
Please run this cell first to restore the best model
"""

# restore the best checkpoint 
Gen = Generator()
Dis = Discriminator()
g_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0, beta_2=0.9)
d_optimizer = tf.keras.optimizers.Adam(4e-4, beta_1=0, beta_2=0.9)

best = 10
checkpoint_dir = './ckpt/sn/'
checkpoint_best_prefix = os.path.join(checkpoint_dir, "ckpt-"+str(best))
checkpoint = tf.train.Checkpoint(g_optimizer=g_optimizer, d_optimizer=d_optimizer, Gen=Gen, Dis=Dis)
checkpoint.restore(checkpoint_best_prefix)

"""## Show Image grid
This cell will use random noise to create a 8*8 image grid
"""

best = 10
label= tf.squeeze(tf.one_hot(tf.random.uniform([batch_size, 1], minval=0, maxval=9, dtype=tf.dtypes.int32), depth=10, on_value=1.0, off_value=0.0, axis=-1) )
noise = tf.concat([tf.random.normal([batch_size, 100]), label], axis=-1)
generate_and_save_images(Gen, best*10, noise, './final_', flag=True)

"""## Show Mean FID
This cell will calculate the mean FID over 10240 TEST data

notice: 240/10240 is duplicated
"""

fid_test = 0
i = 0
for step, img in enumerate(test_data):
  # 10240
    fid = calculate_all_fid(Gen, img, training=False)
    fid_test += fid
    i += 1
    print('{:04d} / {:04d} test imgs, FID score : {:.2f}, please wait... '.format(i*batch_test, 10*batch_test, fid))
    if i >= 10:
        break
fid_test /= 10.
print("The average FID score on total {} test img is :  {:.2f}.".format(10*batch_test, fid_test))